{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1265,
     "status": "ok",
     "timestamp": 1627064948861,
     "user": {
      "displayName": "Luke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgVHa86ZvbOzekf98D-DK7VGFXsqJbLsF_AwwDVkg=s64",
      "userId": "13444062478917277113"
     },
     "user_tz": 420
    },
    "id": "YSx2aexhXLVu"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "import cv2\n",
    "from imutils import face_utils\n",
    "from imutils.video import VideoStream\n",
    "import imutils\n",
    "from fastai.vision import *\n",
    "import argparse\n",
    "import time\n",
    "import dlib\n",
    "from playsound import playsound\n",
    "from torch.serialization import SourceChangeWarning\n",
    "warnings.filterwarnings(\"ignore\", category=SourceChangeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "executionInfo": {
     "elapsed": 207,
     "status": "error",
     "timestamp": 1627064949054,
     "user": {
      "displayName": "Luke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgVHa86ZvbOzekf98D-DK7VGFXsqJbLsF_AwwDVkg=s64",
      "userId": "13444062478917277113"
     },
     "user_tz": 420
    },
    "id": "Kv9p4X0LXMK7",
    "outputId": "1b12e253-cef3-436f-ff86-41c1d6c52dd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./export.pkl\n"
     ]
    }
   ],
   "source": [
    "path = './'\n",
    "print(path + 'export.pkl')\n",
    "learn = load_learner(path, 'export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 196,
     "status": "aborted",
     "timestamp": 1627064949049,
     "user": {
      "displayName": "Luke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgVHa86ZvbOzekf98D-DK7VGFXsqJbLsF_AwwDVkg=s64",
      "userId": "13444062478917277113"
     },
     "user_tz": 420
    },
    "id": "iFgVmQAiXVtD"
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(\"../haarcascade_frontalface_alt2.xml\")\n",
    "vs = VideoStream(src=0).start()\n",
    "start = time.perf_counter()\n",
    "data = []\n",
    "time_value = 0\n",
    "EYE_AR_THRESH = 0.20\n",
    "EYE_AR_CONSEC_FRAMES = 10\n",
    "COUNTER = 0\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "def data_time(time_value, prediction, probability, ear):\n",
    "    current_time = int(time.perf_counter()-start)\n",
    "    if current_time != time_value:\n",
    "        data.append([current_time, prediction, probability, ear])\n",
    "        time_value = current_time\n",
    "    return time_value\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the emotion\n",
    "def test_emotion(emotion, vs):\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=450)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    face_coord = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(30, 30))\n",
    "    return \n",
    "\n",
    "# To start the game you will press q. Once pressed the first emotion you will\n",
    "# make is neutral. If you do make the emotion for 3 seconds you get a correct\n",
    "# noise and if not it will give an incorrect noise. There will be a noises\n",
    "# introducing all the emotions and noises to say you passed or you did not pass.\n",
    "# This will go in order after neutral to happy, sad, surprised, then angry. Once\n",
    "# you go through all emotions correctly you win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 197,
     "status": "aborted",
     "timestamp": 1627064949051,
     "user": {
      "displayName": "Luke",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgVHa86ZvbOzekf98D-DK7VGFXsqJbLsF_AwwDVkg=s64",
      "userId": "13444062478917277113"
     },
     "user_tz": 420
    },
    "id": "sRtlQIIyXzB2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You passed the neutral round\n",
      "You passed the happy round\n",
      "You passed the sad round\n",
      "You passed the surprise round\n",
      "You passed the angry round\n"
     ]
    }
   ],
   "source": [
    "emotions = ['neutral','happy', 'sad', 'surprise', 'angry'] # put the emotions\n",
    "FRAMES_TO_PASS = 6\n",
    "for emotion in emotions:\n",
    "    emotion_counter = 0\n",
    "    first_pass = True\n",
    "    while True:\n",
    "        frame = vs.read()\n",
    "        frame = imutils.resize(frame, width=450)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        face_coord = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(30, 30))\n",
    "        cv2.putText(frame, f\"Make a {emotion} face!\", (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "        for coords in face_coord:\n",
    "            X, Y, w, h = coords\n",
    "            H, W, _ = frame.shape\n",
    "            X_1, X_2 = (max(0, X - int(w * 0.3)), min(X + int(1.3 * w), W))\n",
    "            Y_1, Y_2 = (max(0, Y - int(0.3 * h)), min(Y + int(1.3 * h), H))\n",
    "            img_cp = gray[Y_1:Y_2, X_1:X_2].copy()\n",
    "            prediction, idx, probability = learn.predict(Image(pil2tensor(img_cp, np.float32).div_(225)))\n",
    "            cv2.rectangle(\n",
    "                img=frame,\n",
    "                pt1=(X_1, Y_1),\n",
    "                pt2=(X_2, Y_2),\n",
    "                color=(128, 128, 0),\n",
    "                thickness=2,\n",
    "            )\n",
    "            rect = dlib.rectangle(X, Y, X+w, Y+h)\n",
    "            cv2.putText(frame, str(prediction), (10, frame.shape[0] - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (225, 255, 255), 2)\n",
    "            cv2.putText(frame, \"Press q to quit\", (250, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "            shape = predictor(gray, rect)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "        if str(prediction) == emotion:\n",
    "            emotion_counter += 1\n",
    "        if emotion_counter > FRAMES_TO_PASS:\n",
    "            playsound('../sounds/correct.mp3')\n",
    "            cv2.imshow(\"frame\", frame)\n",
    "            cv2.putText(frame, f\"You passed the {emotion} round!\", (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            print(f'You passed the {emotion} round')\n",
    "            break\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        if first_pass:\n",
    "            playsound('../sounds/' + emotion + '.mp3')\n",
    "            first_pass = False\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\") :\n",
    "            vs.stop()\n",
    "            cv2.destroyAllWindows()\n",
    "            cv2.waitKey(1)\n",
    "            break\n",
    "# End the game\n",
    "playsound('../sounds/win.mp3')\n",
    "while True:\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=450)\n",
    "    cv2.putText(frame, \"You win!!!\", (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\") :\n",
    "        vs.stop()\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOkj85hsj+ogjoLIb4iSXbU",
   "name": "LiveVideoFrame.pynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
